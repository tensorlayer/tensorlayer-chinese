<!--<div align="center">
	<div class="TensorFlow">
  <img src="https://www.tensorflow.org/images/tf_logo_transp.png" style=": left; margin-left: 5px; margin-bottom: 5px;"><br><br>
   </div>
   <div class="TensorLayer">
    <img src="https://www.tensorflow.org/images/tf_logo_transp.png" style=": right; margin-left: 5px; margin-bottom: 5px;">
    </div>
</div>
-->
<a href="http://tensorlayer.readthedocs.io">
<div align="center">
	<img src="img/img_tensorlayer.png" width="30%" height="30%"/>
</div>
</a>


# TensorLayer: é¢å‘ç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆçš„æ·±åº¦å­¦ä¹ å’Œå¢å¼ºå­¦ä¹ åº“  

TensorLayer æ˜¯ä¸ºç ”ç©¶äººå‘˜å’Œå·¥ç¨‹å¸ˆè®¾è®¡çš„ä¸€æ¬¾åŸºäº[Google TensorFlow](https://www.tensorflow.org)å¼€å‘çš„æ·±åº¦å­¦ä¹ ä¸å¢å¼ºå­¦ä¹ åº“åº“ã€‚ 
å®ƒæä¾›é«˜çº§åˆ«çš„ï¼ˆHigher-Levelï¼‰æ·±åº¦å­¦ä¹ APIï¼Œè¿™æ ·ä¸ä»…å¯ä»¥åŠ å¿«ç ”ç©¶äººå‘˜çš„å®éªŒé€Ÿåº¦,ä¹Ÿèƒ½å¤Ÿå‡å°‘å·¥ç¨‹å¸ˆåœ¨å®é™…å¼€å‘å½“ä¸­çš„é‡å¤å·¥ä½œã€‚
TensorLayeréå¸¸æ˜“äºä¿®æ”¹å’Œæ‰©å±•ï¼Œè¿™ä½¿å®ƒå¯ä»¥åŒæ—¶ç”¨äºæœºå™¨å­¦ä¹ çš„ç ”ç©¶ä¸åº”ç”¨ã€‚æ­¤å¤–ï¼ŒTensorLayer æä¾›äº†å¤§é‡ç¤ºä¾‹å’Œæ•™ç¨‹æ¥å¸®åŠ©åˆå­¦è€…ç†è§£æ·±åº¦å­¦ä¹ ï¼Œå¹¶æä¾›å¤§é‡çš„å®˜æ–¹ä¾‹å­ç¨‹åºæ–¹ä¾¿å¼€å‘è€…å¿«é€Ÿæ‰¾åˆ°é€‚åˆè‡ªå·±é¡¹ç›®çš„ä¾‹å­ã€‚

é˜…è¯»TensorLayer Readthedocs æ–‡æ¡£æ‚¨ä¸ä»…å¯ä»¥å­¦ä¼šå¦‚ä½•ä½¿ç”¨è¿™ä¸ªåº“ï¼Œä¹Ÿä¼šäº†è§£ä¸åŒç±»å‹çš„ç¥ç»ç½‘ç»œã€æ·±åº¦å­¦ä¹ ã€å¼ºåŒ–å­¦ä¹ ï¼Œè¿˜æœ‰è‡ªç„¶è¯­è¨€å¤„ç†ç­‰å†…å®¹ã€‚

ä¸è¿‡ï¼Œä¸å…¶å®ƒåŸºäºTensorFlowå¼€å‘çš„å‚»ç“œå¼APIä¸åŒï¼ŒTensorLayeréœ€è¦ä½¿ç”¨è€…æœ‰åŸºæœ¬çš„ç¥ç»ç½‘ç»œçŸ¥è¯†ã€‚äº†è§£TensorFlowçš„åŸºç¡€ï¼Œå¯ä»¥è®©ç”¨éå¸¸ç†Ÿç»ƒåœ°ä½¿ç”¨å®ƒã€‚

ğŸ†•ğŸ†•ğŸ†• æœºå™¨ç¿»è¯‘ï¼ˆMachine Translationï¼‰çš„ç›¸å…³æ•™ç¨‹å·²ç»å‘å¸ƒï¼

TensorLayer åœ¨å…¼é¡¾ TensorFlow çš„çµæ´»æ€§çš„åŒæ—¶ï¼Œåˆèƒ½ä¸ºä½¿ç”¨è€…æä¾›åˆé€‚çš„æ“ä½œç²’åº¦æ¥å»ºç«‹å’Œè®­ç»ƒç¥ç»ç½‘ç»œã€‚TensorLayerçš„å¼€å‘éµå¾ªä»¥ä¸‹å‡ ä¸ªåŸåˆ™ï¼š

- é€æ˜æ€§ï¼šç”¨æˆ·å¯ä»¥ç›´æ¥ä½¿ç”¨ TensorFlow çš„æ–¹æ³•æ¥æ“ä½œæ‰€æœ‰æœ‰çš„è®­ç»ƒï¼Œè¿­ä»£ï¼Œåˆå§‹åŒ–è¿‡ç¨‹ï¼Œæˆ‘ä»¬é¼“åŠ±ç”¨æˆ·å°½å¯èƒ½å¤šçš„åœ¨TensorLayerä¸­ä½¿ç”¨TensorFlowçš„æ–¹æ³•ï¼Œåˆ©ç”¨TensorFlowæ‰€æä¾›çš„ä¾¿åˆ©ã€‚
- å¼ é‡ï¼šå¼ é‡æ˜¯ä¸€ä¸ªå¯ç”¨æ¥è¡¨ç¤ºåœ¨ä¸€äº›å‘é‡ã€æ ‡é‡å’Œå…¶ä»–å¼ é‡ä¹‹é—´çš„çº¿æ€§å…³ç³»çš„å¤šçº¿æ€§å‡½æ•°ã€‚TensorFlow ä½¿ç”¨è¿™ç§æ•°æ®ç»“æ„æ¥è¡¨ç¤ºç¥ç»ç½‘ç»œæ‰€éœ€è¦çš„æ•°æ®ã€‚
- æ•™ç¨‹ï¼šTensorLayeræä¾›äº†å¤§é‡çš„è¿è´¯æ•™ç¨‹ï¼Œè®©ç”¨æˆ·å¯ä»¥å¾ªåºæ¸è¿›çš„å­¦ä¹ ä½¿ç”¨TensorLayerå’Œæ·±åº¦å­¦ä¹ äº†è§£ï¼Œæ•™ç¨‹çš„å†…å®¹è¦†ç›–äº† Dropout, DropConnect, Denoising Autoencoder, LSTM, CNN ç­‰ç­‰ã€‚
- TPUï¼šTensor Process Unit æ˜¯ä¸ºäº†é’ˆå¯¹ TensorFlow æ·±åº¦å­¦ä¹ æ‰“é€ çš„å®šåˆ¶åŒ–ASICèŠ¯ç‰‡ã€‚
- åˆ†å¸ƒå¼ï¼šTensorFlow é»˜è®¤æ”¯æŒåˆ†å¸ƒå¼ç³»ç»Ÿã€‚
- å…¼å®¹æ€§ï¼šå•å±‚ç½‘ç»œçš„å»ºç«‹è¢«æŠ½è±¡æˆæ­£åˆ™åŒ–ï¼Œæˆæœ¬å’Œæ¯ä¸€å±‚çš„è¾“å‡ºï¼Œæ–¹ä¾¿ä¸å…¶ä»–åŸºäºTensorFlowçš„åº“åä½œã€‚
- ç®€æ´ï¼šæ˜“äºä½¿ç”¨ï¼Œæ‰©å±•ä¸ä¿®æ”¹ï¼Œä»¥ä¾¿åœ¨ç ”ç©¶å’Œå·¥ç¨‹ä¸­ä½¿ç”¨ã€‚
- é«˜é€Ÿï¼šåœ¨GPUçš„æ”¯æŒä¸‹è¿è¡Œé€Ÿåº¦ä¸çº¯TensorFlowè„šæœ¬é€Ÿåº¦ä¸€è‡´ã€‚ç®€æ´ä½†ä¸ç‰ºç‰²æ€§èƒ½ã€‚

è®©æˆ‘ä»¬åœ¨ [overview](#overview) ä¸­çœ‹çœ‹TensorLayerå¼ºå¤§çš„åŠŸèƒ½å§!!!


æ³¨æ„ï¼šæœ¬repoæ˜¯[TensorLayer Github](https://github.com/zsdonghao/tensorlayer)çš„ç¿»è¯‘ç‰ˆï¼Œæ›´æ–°é€Ÿåº¦ä¼šæ¯”è‹±æ–‡åŸç‰ˆæ…¢ï¼Œè‹¥ä½ çš„è‹±æ–‡å¾ˆå¥½ï¼Œæˆ‘ä»¬å»ºè®®ä½ ç›´æ¥é˜…è¯»[è‹±æ–‡æ–‡æ¡£](http://tensorlayer.readthedocs.io/)ã€‚


-

####ğŸ‡¨ğŸ‡³ä¸ºäº†ä¿ƒè¿›åäººå¼€å‘è€…çš„äº¤æµé€Ÿåº¦ï¼Œæˆ‘ä»¬å»ºç«‹äº†å¤šç§äº¤æµæ¸ é“ï¼Œæ‚¨å¯æŠŠå¾®ä¿¡å·å‘é€åˆ° haodong_cs@163.com ç”³è¯·åŠ å…¥ã€‚

####ğŸ‡¹ğŸ‡­à¹€à¸£à¸²à¸‚à¸­à¹€à¸£à¸µà¸¢à¸™à¹€à¸Šà¸´à¸à¸™à¸±à¸à¸à¸±à¸’à¸™à¸²à¸„à¸™à¹„à¸—à¸¢à¸—à¸¸à¸à¸„à¸™à¸—à¸µà¹ˆà¸ªà¸™à¹ƒà¸ˆà¸ˆà¸°à¹€à¸‚à¹‰à¸²à¸£à¹ˆà¸§à¸¡à¸—à¸µà¸¡à¸à¸±à¸’à¸™à¸² TensorLayer à¸•à¸´à¸”à¸•à¹ˆà¸­à¸ªà¸­à¸šà¸–à¸²à¸¡à¸£à¸²à¸¢à¸¥à¸°à¹€à¸­à¸µà¸¢à¸”à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡à¹„à¸”à¹‰à¸—à¸µà¹ˆ haodong_cs@163.com

####ğŸ‡¬ğŸ‡§If you are in London, we can discuss face to face.

-

# Readme ç›®å½•
0. [åº“ç›®å½• Library Structure](#Library-Structure)
0. [æ¦‚è¿° Overview](#Overview)
0. [å¦‚ä½•ä¿®æ”¹ Easy to Modify](#Easytomodify)
0. [å®‰è£…æ­¥éª¤ Installation](#Installation)
0. [å‚ä¸å¼€å‘ Ways to Contribute](#Waystocontribute)
0. [è‹±æ–‡åœ¨çº¿æ–‡æ¡£ Online Documentation](http://tensorlayer.readthedocs.io/)
0. [ä¸‹è½½è‹±æ–‡ PDF](https://media.readthedocs.org/pdf/tensorlayer/latest/tensorlayer.pdf)
0. [ä¸‹è½½è‹±æ–‡ Epub](http://readthedocs.org/projects/tensorlayer/downloads/epub/latest/)
0. [ä¸‹è½½è‹±æ–‡ HTML](http://readthedocs.org/projects/tensorlayer/downloads/htmlzip/latest/)
0. [ä¸­æ–‡åœ¨çº¿æ–‡æ¡£ Online Documentation](http://tensorlayercn.readthedocs.io/)
0. [ä¸‹è½½ä¸­æ–‡ PDF](https://media.readthedocs.org/pdf/tensorlayercn/latest/tensorlayercn.pdf)
0. [ä¸‹è½½ä¸­æ–‡ Epub](http://readthedocs.org/projects/tensorlayercn/downloads/epub/latest/)
0. [ä¸‹è½½ä¸­æ–‡ HTML](http://readthedocs.org/projects/tensorlayercn/downloads/htmlzip/latest/)

--
# åº“ç›®å½•

[TensorLayer å®˜æ–¹ Github](https://github.com/zsdonghao/tensorlayer)çš„ç›®å½•å¦‚ä¸‹ã€‚

```
<folder>
â”œâ”€â”€ tensorlayer  		<--- library source code
â”‚
â”œâ”€â”€ setup.py			<--- use â€˜python setup.py installâ€™ or â€˜pip install . -eâ€˜, to install
â”œâ”€â”€ docs 				<--- readthedocs folder
â”‚   â””â”€â”€ _build          <--- not included in the remote repo but can be generated in `docs` using `make html`
â”‚   	 â””â”€â”€html
â”‚			 â””â”€â”€index.html <--- homepage of the documentation
â”œâ”€â”€ tutorials_*.py	 	<--- tutorials include NLP, DL, RL etc.
â”œâ”€â”€ .. 
```
--
# æ¦‚è¿°
More examples about Deep Learning, Reinforcement Learning and Nature Language Processing available on *[Read the Docs](http://tensorlayer.readthedocs.io/en/latest/)*, you can also download the docs file then read it locally.

0. [Fully Connected Network](#)
0. [Convolutional Neural Network](#)
0. [Recurrent Neural Network](#)
0. [Reinforcement Learning](#)
0. [Cost Function](#)

### *å¤šå±‚ç¥ç»ç½‘ç»œ*
TensorLayer provides large amount of state-of-the-art Layers including Dropout, DropConnect, ResNet, Pre-train and so on.

**<font color="grey"> Placeholder: </font>**

All placeholder and variables can be initialized by the same way with Tensorflow's tutorial. For details please read *[tensorflow-placeholder](https://www.tensorflow.org/versions/master/api_docs/python/io_ops.html#placeholder)*, *[tensorflow-variables](https://www.tensorflow.org/versions/master/how_tos/variables/index.html)* and *[tensorflow-math](https://www.tensorflow.org/versions/r0.9/api_docs/python/math_ops.html)*.

```python
# For MNIST example, 28x28 images have 784 pixels, i.e, 784 inputs.
import tensorflow as tf
import tensorlayer as tl
x = tf.placeholder(tf.float32, shape=[None, 784], name='x')
y_ = tf.placeholder(tf.int64, shape=[None, ], name='y_')
```

**<font color="grey"> Rectifying Network with Dropout: </font>**

```python
# Define the network
network = tl.layers.InputLayer(x, name='input_layer')
network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')
network = tl.layers.DenseLayer(network, n_units=800, act = tf.nn.relu, name='relu1')
network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')
network = tl.layers.DenseLayer(network, n_units=800, act = tf.nn.relu, name='relu2')
network = tl.layers.DropoutLayer(network, keep=0.5, name='drop3')
network = tl.layers.DenseLayer(network, n_units=10, act = tl.activation.identity, name='output_layer')
# Start training
...
```
**<font color="grey"> æ™®é€šç¨€ç–è‡ªç¼–ç å™¨ Vanilla Sparse Autoencoder: </font>**


```python
# å®šä¹‰ç½‘ç»œ
network = tl.layers.InputLayer(x, name='input_layer')
network = tl.layers.DenseLayer(network, n_units=196, act = tf.nn.sigmoid, name='sigmoid1')
recon_layer1 = tl.layers.ReconLayer(network, x_recon=x, n_units=784, act = tf.nn.sigmoid, name='recon_layer1')
# å¼€å§‹é¢„è®­ç»ƒ
sess.run(tf.initialize_all_variables())
recon_layer1.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name=None, n_epoch=200, batch_size=128, print_freq=10, save=True, save_name='w1pre_')
...
```
**<font color="grey"> å»å™ªè‡ªç¼–ç å™¨ Denoising Autoencoder: </font>**


```python
# å®šä¹‰ç½‘ç»œ
network = tl.layers.InputLayer(x, name='input_layer')
network = tl.layers.DropoutLayer(network, keep=0.5, name='denoising1')   
network = tl.layers.DenseLayer(network, n_units=196, act = tf.nn.relu, name='relu1')
recon_layer1 = tl.layers.ReconLayer(network, x_recon=x, n_units=784, act = tf.nn.softplus, name='recon_layer1')
# å¼€å§‹é¢„è®­ç»ƒ
sess.run(tf.initialize_all_variables())
recon_layer1.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name='denoising1', n_epoch=200, batch_size=128, print_freq=10, save=True, save_name='w1pre_')
...
```

**<font color="grey"> å †æ ˆå¼å»å™ªè‡ªç¼–ç å™¨ Stacked Denoising Autoencoder: </font>**

```python
# å®šä¹‰ç½‘ç»œ
network = tl.layers.InputLayer(x, name='input_layer')
# denoise layer for Autoencoders
network = tl.layers.DropoutLayer(network, keep=0.5, name='denoising1')
# 1st layer
network = tl.layers.DropoutLayer(network, keep=0.8, name='drop1')
network = tl.layers.DenseLayer(network, n_units=800, act = tf.nn.relu, name='relu1')
x_recon1 = network.outputs
recon_layer1 = tl.layers.ReconLayer(network, x_recon=x, n_units=784, act = tf.nn.softplus, name='recon_layer1')
# 2nd layer
network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')
network = tl.layers.DenseLayer(network, n_units=800, act = tf.nn.relu, name='relu2')
recon_layer2 = tl.layers.ReconLayer(network, x_recon=x_recon1, n_units=800, act = tf.nn.softplus, name='recon_layer2')
# 3rd layer
network = tl.layers.DropoutLayer(network, keep=0.5, name='drop3')
network = tl.layers.DenseLayer(network, n_units=10, act = tl.activation.identity, name='output_layer')

sess.run(tf.initialize_all_variables())

# æ˜¾ç¤ºæ¨¡å‹å‚æ•°ä¿¡æ¯
network.print_params()

# å¼€å§‹é¢„è®­ç»ƒ Layer 1
recon_layer1.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name='denoising1', n_epoch=100, batch_size=128, print_freq=10, save=True, save_name='w1pre_')
# å¼€å§‹é¢„è®­ç»ƒ Layer 2
recon_layer2.pretrain(sess, x=x, X_train=X_train, X_val=X_val, denoise_name='denoising1', n_epoch=100, batch_size=128, print_freq=10, save=False)
# å¼€å§‹è®­ç»ƒ, å¾®è°ƒ fine-tune
...
```

### *å·ç§¯ç¥ç»ç½‘ç»œ Convolutional Neural Network*

Instead of feeding the images as 1D vectors, the images can be imported as 4D matrix, where [None, 28, 28, 1] represents [batchsize, height, width, channels]. Set 'batchsize' to 'None' means data with different batchsize can all filled into the placeholder.

```python
x = tf.placeholder(tf.float32, shape=[None, 28, 28, 1])
y_ = tf.placeholder(tf.int64, shape=[None,])
```

**<font color="grey"> CNNs + MLP: </font>**

A 2 layers CNN followed by 2 fully connected layers can be defined by the following codes:

```python
network = tl.layers.InputLayer(x, name='input_layer')
network = tl.layers.Conv2dLayer(network,
                        act = tf.nn.relu,
                        shape = [5, 5, 1, 32],  # 32 features for each 5x5 patch
                        strides=[1, 1, 1, 1],
                        padding='SAME',
                        name ='cnn_layer1')     # output: (?, 28, 28, 32)
network = tl.layers.Pool2dLayer(network,
                        ksize=[1, 2, 2, 1],
                        strides=[1, 2, 2, 1],
                        padding='SAME',
                        pool = tf.nn.max_pool,
                        name ='pool_layer1',)   # output: (?, 14, 14, 32)
network = tl.layers.Conv2dLayer(network,
                        act = tf.nn.relu,
                        shape = [5, 5, 32, 64], # 64 features for each 5x5 patch
                        strides=[1, 1, 1, 1],
                        padding='SAME',
                        name ='cnn_layer2')     # output: (?, 14, 14, 64)
network = tl.layers.Pool2dLayer(network,
                        ksize=[1, 2, 2, 1],
                        strides=[1, 2, 2, 1],
                        padding='SAME',
                        pool = tf.nn.max_pool,
                        name ='pool_layer2',)   # output: (?, 7, 7, 64)
network = tl.layers.FlattenLayer(network, name='flatten_layer')                                # output: (?, 3136)
network = tl.layers.DropoutLayer(network, keep=0.5, name='drop1')                              # output: (?, 3136)
network = tl.layers.DenseLayer(network, n_units=256, act = tf.nn.relu, name='relu1')           # output: (?, 256)
network = tl.layers.DropoutLayer(network, keep=0.5, name='drop2')                              # output: (?, 256)
network = tl.layers.DenseLayer(network, n_units=10, act = tl.activation.identity, name='output_layer')    # output: (?, 10)
```
For more powerful functions, please go to *[Read the Docs](http://tensorlayer.readthedocs.io/en/latest/)*.


### *é€’å½’ç¥ç»ç½‘ç»œ Recurrent Neural Network*

**<font color="grey"> LSTM: </font>** 

Please go to *[Understand LSTM](http://tensorlayer.readthedocs.io/en/latest/user/tutorial.html#run-the-ptb-example)*.


### *Reinforcement Learning*
To understand Reinforcement Learning, a Blog (*[Deep Reinforcement Learning: Pong from Pixels](http://karpathy.github.io/2016/05/31/rl/)*) and a Paper (*[Playing Atari with Deep Reinforcement Learning](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf)*) are recommended. To play with RL, use *[OpenAI Gym](https://github.com/openai/gym)* as benchmark is recommended.

**<font color="grey"> Pong Game: </font>**

Atari Pong Game is a single agent example. *[Pong from Pixels](http://karpathy.github.io/2016/05/31/rl/)* using 130 lines of Python only *[(Code link)](https://gist.github.com/karpathy/a4166c7fe253700972fcbc77e4ea32c5)* can be reimplemented as follow.

```python
# Policy network
network = tl.layers.InputLayer(x, name='input_layer')
network = tl.layers.DenseLayer(network, n_units= H , act = tf.nn.relu, name='relu_layer')
network = tl.layers.DenseLayer(network, n_units= 1 , act = tf.nn.sigmoid, name='output_layer')
```

For RL part, please read *[Policy Gradient](http://tensorlayer.readthedocs.io/en/latest/user/tutorial.html#understand-reinforcement-learning)*.



### *æŸå¤±å‡½æ•° Cost Function*

TensorLayer provides a simple way to creat you own cost function. Take a MLP below for example.

```python
network = tl.InputLayer(x, name='input_layer')
network = tl.DropoutLayer(network, keep=0.8, name='drop1')
network = tl.DenseLayer(network, n_units=800, act = tf.nn.relu, name='relu1')
network = tl.DropoutLayer(network, keep=0.5, name='drop2')
network = tl.DenseLayer(network, n_units=800, act = tf.nn.relu, name='relu2')
network = tl.DropoutLayer(network, keep=0.5, name='drop3')
network = tl.DenseLayer(network, n_units=10, act = tl.activation.identity, name='output_layer')
```

**<font color="grey"> å‚æ•°è§„åˆ™åŒ– Regularization of Weights: </font>**

After initializing the variables, the informations of network parameters can be observed by using **<font color="grey">network.print_params()</font>**.

```python
sess.run(tf.initialize_all_variables())
network.print_params()
>> param 0: (784, 800) (mean: -0.000000, median: 0.000004 std: 0.035524)
>> param 1: (800,) (mean: 0.000000, median: 0.000000 std: 0.000000)
>> param 2: (800, 800) (mean: 0.000029, median: 0.000031 std: 0.035378)
>> param 3: (800,) (mean: 0.000000, median: 0.000000 std: 0.000000)
>> param 4: (800, 10) (mean: 0.000673, median: 0.000763 std: 0.049373)
>> param 5: (10,) (mean: 0.000000, median: 0.000000 std: 0.000000)
>> num of params: 1276810
```

The output of network is **<font color="grey">network.outputs</font>**, then the cross entropy can be defined as follow. Besides, to regularize the weights, the **<font color="grey">network.all_params</font>** contains all parameters of the network. In this case, **<font color="grey">network.all_params</font>** = [W1, b1, W2, b2, Wout, bout] according to param 0, 1 ... 5 shown by **<font color="grey">network.print_params()</font>**. Then max-norm regularization on W1 and W2 can be performed as follow.

```python
y = network.outputs
cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(y, y_))
cost = cross_entropy
cost = cost + tl.cost.maxnorm_regularizer(1.0)(network.all_params[0]) + tl.cost.maxnorm_regularizer(1.0)(network.all_params[2])
```
In addition, all TensorFlow's regularizers like **<font color="grey">tf.contrib.layers.l2_regularizer</font>** can be used with TensorLayer.

**<font color="grey"> Regularization of Activation Outputs: </font>**

Instance method **<font color="grey">network.print_layers()</font>** prints all outputs of different layers in order. To achieve regularization on activation output, you can use **<font color="grey">network.all_layers</font>** which contains all outputs of different layers. If you want to use L1 penalty on the activations of first hidden layer, just simply add **<font color="grey">tf.contrib.layers.l2_regularizer(lambda_l1)(network.all_layers[1])</font>** to the cost function.

```python
network.print_layers()
>> layer 0: Tensor("dropout/mul_1:0", shape=(?, 784), dtype=float32)
>> layer 1: Tensor("Relu:0", shape=(?, 800), dtype=float32)
>> layer 2: Tensor("dropout_1/mul_1:0", shape=(?, 800), dtype=float32)
>> layer 3: Tensor("Relu_1:0", shape=(?, 800), dtype=float32)
>> layer 4: Tensor("dropout_2/mul_1:0", shape=(?, 800), dtype=float32)
>> layer 5: Tensor("add_2:0", shape=(?, 10), dtype=float32)
```
For more powerful functions, please go to *[Read the Docs](http://tensorlayer.readthedocs.io/en/latest/)*.

# Easy to Modify
**<font color="grey"> Modifying Pre-train Behaviour: </font>**


Greedy layer-wise pretrain is an important task for deep neural network initialization, while there are many kinds of pre-train metrics according to different architectures and applications.

For example, the pre-train process of *[Vanilla Sparse Autoencoder](http://deeplearning.stanford.edu/wiki/index.php/Autoencoders_and_Sparsity)* can be implemented by using KL divergence as the following code, but for *[Deep Rectifier Network](http://www.jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf)*, the sparsity can be implemented by using the L1 regularization of activation output.

```python
# æ™®é€šç¨€ç–è‡ªç¼–ç å™¨ Vanilla Sparse Autoencoder
beta = 4
rho = 0.15
p_hat = tf.reduce_mean(activation_out, reduction_indices = 0)
KLD = beta * tf.reduce_sum( rho * tf.log(tf.div(rho, p_hat)) + (1- rho) * tf.log((1- rho)/ (tf.sub(float(1), p_hat))) )
```

For this reason, TensorLayer provides a simple way to modify or design your own pre-train metrice. For Autoencoder, TensorLayer uses **ReconLayer.*__*init__()** to define the reconstruction layer and cost function, to define your own cost function, just simply modify the **self.cost** in **ReconLayer.*__*init__()**. To creat your own cost expression please read *[Tensorflow Math](https://www.tensorflow.org/versions/master/api_docs/python/math_ops.html)*. By default, **ReconLayer** only updates the weights and biases of previous 1 layer by using **self.train_params = self.all _params[-4:]**, where the 4 parameters are [W_encoder, b_encoder, W_decoder, b_decoder]. If you want to update the parameters of previous 2 layers, simply modify **[-4:]** to **[-6:]**.


```python    
ReconLayer.__init__(...):
    ...
    self.train_params = self.all_params[-4:]
    ...
	self.cost = mse + L1_a + L2_w
```

**<font color="grey"> Adding Customized Regularizer: </font>**

See tensorlayer/cost.py


# å®‰è£…æ­¥éª¤

**<font color="grey"> å®‰è£… TensorFlowï¼š</font>**

è¯·é¢„å…ˆå®‰è£…TensorFlowï¼Œå®ƒçš„ç‰ˆæœ¬éœ€è¦ >= 0.8ï¼š *[Tensorflow å®‰è£…æŒ‡å—ï¼ˆè‹±æ–‡ç‰ˆï¼‰](https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html)*ã€‚

**<font color="grey"> è®¾ç½® GPUï¼š</font>**

TensorFlow GPUç‰ˆéœ€è¦ä½ å…ˆå®‰è£… CUDA å’Œ cuDNNï¼š

*[CUDA, CuDNN å®‰è£…æŒ‡å—ï¼ˆè‹±æ–‡ç‰ˆï¼‰](https://www.tensorflow.org/versions/master/get_started/os_setup.html#optional-install-cuda-gpus-on-linux)*

*[CUDA ä¸‹è½½](https://developer.nvidia.com/cuda-downloads)*

*[cuDNN ä¸‹è½½](https://developer.nvidia.com/cudnn)*

**<font color="grey"> å®‰è£… TensorLayerï¼š</font>**

ä½ å¯ä»¥è·Ÿç€ä¸‹é¢çš„æ­¥éª¤å®‰è£…TensorLayerï¼Œè¯¦ç»†è¯·å‚è€ƒ [Read the Docs](http://tensorlayercn.readthedocs.io/zh/latest/user/installation.html)ã€‚

```python
python setup.py install
or
pip install . -e
```


# å‚ä¸å¼€å‘

TensorLayer å§‹äºå¸å›½ç†å·¥å¤§å­¦çš„å†…éƒ¨é¡¹ç›®ï¼Œä¸»è¦ç”¨äºå¸®åŠ©ç§‘ç ”å·¥ä½œè€…æµ‹è¯•ä»–ä»¬çš„ä¸€äº›æƒ³æ³•å’Œç®—æ³•ã€‚ç„¶è€Œç°åœ¨æˆ‘ä»¬é¼“åŠ±ä¸–ç•Œå„åœ°çš„ç ”ç©¶è€…å‘å¸ƒè‡ªå·±çš„æ–¹æ³•ç”¨ä»¥ä¿ƒè¿›å’ŒåŠ å¿«æœºå™¨å­¦ä¹ çš„è¿›ä¸€æ­¥å‘å±•ã€‚

å¦‚æœä½ å¯ä»¥è¯æ˜ä½ çš„ç®—æ³•æ¯”ç°æœ‰çš„æ–¹æ³•æ›´å¿«æ›´å¥½æ›´æœ‰æ•ˆï¼Œæˆ‘ä»¬å°†ä¼šæŠŠå®ƒåŠ å…¥åˆ°TensorLayerä¸­ã€‚è¯·åŒæ—¶æä¾›æµ‹è¯•ç”¨çš„æ–‡ä»¶å’Œå…·ä½“çš„ç®—æ³•æè¿°ã€‚

# ç½‘ä¸Šæ–‡æ¡£
ç½‘ä¸Šæ–‡æ¡£è¢«æ”¾åœ¨äº† [Read the Docs](http://tensorlayercn.readthedocs.io/zh/latest/)ã€‚å¦‚æœä½ æƒ³åœ¨æœ¬åœ°ç”Ÿæˆè¿™äº›æ–‡æ¡£ï¼Œä¹Ÿå¯ä»¥è·Ÿç€ä¸‹é¢çš„æ­¥éª¤ï¼š
```shell
cd docs
make html
```

# æ–‡æ¡£

0. [è‹±æ–‡åœ¨çº¿æ–‡æ¡£ Online Documentation](http://tensorlayer.readthedocs.io/)
0. [ä¸‹è½½è‹±æ–‡ PDF](https://media.readthedocs.org/pdf/tensorlayer/latest/tensorlayer.pdf)
0. [ä¸‹è½½è‹±æ–‡ Epub](http://readthedocs.org/projects/tensorlayer/downloads/epub/latest/)
0. [ä¸‹è½½è‹±æ–‡ HTML](http://readthedocs.org/projects/tensorlayer/downloads/htmlzip/latest/)
0. [ä¸­æ–‡åœ¨çº¿æ–‡æ¡£ Online Documentation](http://tensorlayercn.readthedocs.io/)
0. [ä¸‹è½½ä¸­æ–‡ PDF](https://media.readthedocs.org/pdf/tensorlayercn/latest/tensorlayercn.pdf)
0. [ä¸‹è½½ä¸­æ–‡ Epub](http://readthedocs.org/projects/tensorlayercn/downloads/epub/latest/)
0. [ä¸‹è½½ä¸­æ–‡ HTML](http://readthedocs.org/projects/tensorlayercn/downloads/htmlzip/latest/)
